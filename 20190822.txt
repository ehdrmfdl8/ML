2019. 8.22

 * pandas에서 missing data만 추출하는 세 가지 고급 기법
	isna
		예) mpg[mpg.isna().sum(1)==True]  # missing data가 있는 
	where

	curry

 * pandas에서 missing data만 제거하는 방법
	dropna
	fillna
	sklearn.preprocessing.Imputer
		sklearn.preprocessing import Imputer

 * numpy의 axis=0은 열(가로줄, row), axis=1은 행(세로줄, column)을 의미함  
 * pandas의 axis 개념은 numpy에서 가져옴

 * 행렬의 개념 정리
	- 행 = 세로줄 = column
	

 * '일반화된 성능(한 번도 본적이 없는 data에 대한 성능)'이 좋아야 한다.

 * 예측 성능 비교하기
    1. 예측용 data 생성
	- sklearn.model_selection.train_test_split 을 사용

       예) from sklearn.model_selection import train_test_split
            # 결과값의 개수 확인  =>  2개라는게 확인됨
            len(train_test_split(mpg))

            # 결과값 만큼 return 얻음
            a, b = train_test_split(mpg)
            len(a)  # train set 개수
            len(b)  # test set 개수

            # 이를 활용해서 train set과 test set을 정의함
            # a => train,  b => test
            train, test = train_test_split(mpg)
            len(train)  # train set 개수
            len(test)  # test set 개수


            # 결과값의 개수 확인  =>  4개라는게 확인됨
            len(train_test_split(mpg.iloc[:,1:], mpg.iloc[:, 0]))

            # 결과값 만큼 return 얻음
            a, b, c, d = train_test_split(mpg.iloc[:,1:], mpg.iloc[:, 0])
            len(a)  # 첫 번째 train set 개수
            len(b)  # 첫 번째 test set 개수
            len(c)  # 두 번째 train set 개수
            len(d)  # 두 번째 test set 개수

            # 이를 활용해서 train set과 test set의 개수를 얻음
            X_train, X_test, y_train, y_test = train_test_split(mpg.iloc[:,1:], mpg.iloc[:, 0])
            len(X_train)  #  X_train set 개수
            len(X_test)  #  X_test set 개수
            len(y_train)  #  y_train set 개수
            len(y_test)  #  y_test set 개수

 * 가장 높은 예측 성능을 찾는 다는 것은 Bias와 Variance가 가장 낮은 예측값을 찾는 것이다.
   Variance가 큰 것을 overfitting이라 함

 * 학습된 데이터나 알고리즘이나 파라메터가 다르면 다른 모델이다.
	GaussianNB

 * 모델 찾기위한 세가지 주요요소
	data, 알고리즘, 하이퍼파라메터
	* 하이퍼파라메터: 
	* 하이퍼파라메터 찾기 유용한 class : GridSearchCV   <= 중요!
		GridSearchCV 해석 :  'CV를 사용하여 최고의 grid를 찾는다'
		signature : GridSearchCV( estimator, param_grid, ... )
			estimator : instance화 된 알고리즘 (KFold, KNeighborsClassifier 등)
			param_grid : 찾을 하이퍼파라메터 대상의 범위 설정
	
	* GridSearchCV.cv_results_  : 대상이 되는 하이퍼파라메터의 grid 범위내 모든 성능 비교 리포트 
	* GridSearchCV.best_params_  : grid 범위내 최적의 하이퍼파라메터를 되돌려줌

	* RandomizedSearchCV : 특정 경우만 추출해서 CV를 찾음.
			=>  속도는 빠르지만, 특정 style data 성격에 따라 최적의 하이퍼파라메터를 잘 못 찾을 수 있음

 * 기계학습 활용하는 GUI 툴 
	- Orange3 : 무료.  퀄은 떨어짐.  대부분의 전처리 된 data에 대해 적합한 예측 모델을 찾아주지만, GridSearchCV 기능은 지원 안 함.
	- 애저(?) : 
	- rapidminer

 * pipeline : datasets로부터 예측모델에서 학습을 시키고, 예측 결과를 도출하는 일련의 과정
	  (pipeline은 일정의 batch와 같은 개념)
	sklearn.pipeline.Pipeline :  pipeline을 적용함.  매우 강력하지만, 많이 복잡하다고 함.
	sklearn.pipeline.make_pipeline :  Pipeline을 간소화 한 것.  대신 Pipeline보다 기능은 떨어짐.
	
	예) from sklearn.pipeline import Pipeline
	

 * 추천도서
	파이썬 날코딩으로 알고 짜는 딥러닝 <= 프레임워크 기본
	밑바닥부터 시작하는 딥러닝
	실체가 손에 잡히는 딥러닝, 
	머신러닝 교과서 with 파이썬	<= 싸이킷 이론중심
	파이썬 라이브 (OREILLY)
	핸즈온 머신러닝 (OREILLY)  <=  싸이킷런 이론중심.  좋은책이지만, 곧 2판 나오므로 지금 사지는 말것!
